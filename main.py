#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Fri Feb 21 15:00:04 2025

@author: ayten
"""

from tensorflow.keras.utils import Sequence
import numpy as np
import matplotlib.pyplot as plt

from dataModel import Train_video_path ,videos,Labels
import utils_func
from deepModel import create3DCNN_BiLSTM
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import precision_score,recall_score
#%%
# class DataGenerator(Sequence):
#     def __init__(self, video_list, batch_size, timesteps, frame_height, frame_width, channels, num_classes):
#         self.video_list = video_list
#         self.batch_size = batch_size
#         self.timesteps = timesteps
#         self.frame_height = frame_height
#         self.frame_width = frame_width
#         self.channels = channels
#         self.num_classes = num_classes

#     def __len__(self):
#         return int(np.floor(len(self.video_list) / self.batch_size))

#     def __getitem__(self, index):
#         batch_videos = self.video_list[index * self.batch_size:(index + 1) * self.batch_size]
#         X, y = self.__data_generation(batch_videos)
#         return X, y

#     def __data_generation(self, batch_videos):
#         X_batch, y_batch = [], []
#         for video in batch_videos:
#             X, y = utils_func.video_sequences( video)  # Video'yu iÅŸle
#             X_batch.append(X)
#             y_batch.append(y)

#         X_batch = np.array(X_batch)
#         y_batch = np.array(y_batch)

#         return X_batch, y_batch
#%%
# Modeli oluÅŸturulur
# Modeli oluÅŸtur

timesteps=30 
num_classes=len(Labels)
frame_height=224 
frame_width=224
channels=3
model = create3DCNN_BiLSTM(timesteps, frame_height, frame_width, channels, num_classes)

# =============================================================================

# #kayÄ±tlÄ± modeli tekrar eÄŸit
# from tensorflow.keras.models import load_model
# from tensorflow.keras.preprocessing.image import ImageDataGenerator
# from tensorflow.keras.optimizers import Adam
# model = load_model('cnn_lstm_model.h5')
# =============================================================================

#%%



# Global history sÃ¶zlÃ¼ÄŸÃ¼nÃ¼ baÅŸlat
global_history = {
    'loss': [],
    'accuracy': [],
    'val_loss': [],
    'val_accuracy': []
}
from tensorflow.keras.callbacks import CSVLogger,EarlyStopping

csv_logger = CSVLogger('training_log.csv', append=True)

#  CSV Logger ve EarlyStopping tanÄ±mla
csv_logger = CSVLogger('training_log.csv', append=True)
early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)


#  Her video iÃ§in artÄ±mlÄ± eÄŸitim
for video in videos:
    print(f"\nğŸ¬ {video} iÃ§in artÄ±mlÄ± eÄŸitim baÅŸlÄ±yor...")

    # Verileri yÃ¼kle
    X_train, y_train, X_val, y_val, X_test, y_test = utils_func.video_sequences(video)
    if X_train is None:
        continue
    # SÄ±nÄ±f aÄŸÄ±rlÄ±klarÄ±nÄ± hesaplama
    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train.argmax(axis=1)), y=y_train.argmax(axis=1))
    class_weight_dict={i: class_weights[i] for i in range(len(class_weights))}
    # Modeli eÄŸit
    history = model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=7,  # her video iÃ§in epoch
        batch_size=8,
        class_weight=class_weight_dict,
        callbacks=[csv_logger, early_stop],
        verbose=1
    )

    # Global metrik geÃ§miÅŸini kaydet (isteÄŸe baÄŸlÄ±)
    for key in global_history.keys():
        global_history[key].extend(history.history.get(key, []))
    
    # Global deÄŸiÅŸkenleri kontrol et ve baÅŸlat
    if 'X_test_global' not in globals():
        X_test_global, y_test_global = X_test, y_test
    else:
        X_test_global = np.concatenate((X_test_global, X_test), axis=0)
        y_test_global = np.concatenate((y_test_global, y_test), axis=0)


# Modeli kaydet
model.save("cnn_lstm_model.h5")

#%%

  # Global test verisiyle nihai deÄŸerlendirme
test_loss, test_acc = model.evaluate(X_test, y_test)
print(f"\nğŸ¯ Global Test DoÄŸruluÄŸu: {test_acc:.2%}")
  

#%%# Model tahmini ve metrik hesaplamalarÄ±
y_pred = model.predict(X_train)
y_pred_classes = np.argmax(y_pred, axis=-1)
y_true_classes = np.argmax(y_train, axis=-1)

# Frame-wise Accuracy Hesaplama
frame_accuracy = np.mean(y_pred_classes == y_true_classes)
print(f"Frame-wise Accuracy: {frame_accuracy:.2f}")

# IoU (Intersection over Union) Hesaplama
def calculate_iou(true_labels, pred_labels):
    intersection = np.logical_and(true_labels, pred_labels).sum()
    union = np.logical_or(true_labels, pred_labels).sum()
    return intersection / union if union > 0 else 0

iou_score = calculate_iou(y_true_classes.flatten(), y_pred_classes.flatten())
print(f"IoU Score: {iou_score:.2f}")

# Event-wise Precision ve Recall Hesaplama
precision = precision_score(y_true_classes.flatten(), y_pred_classes.flatten(), average='macro')
recall = recall_score(y_true_classes.flatten(), y_pred_classes.flatten(), average='macro')
print(f"Event-wise Precision: {precision:.2f}, Recall: {recall:.2f}")
#%%
# Grafik Ã§izme fonksiyonu
def plot_training_history(history):
    epochs = range(1, len(history.history['loss']) + 1)

    # KayÄ±p (Loss) GrafiÄŸi
    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.plot(epochs, history.history['loss'], 'b', label='EÄŸitim KaybÄ±')
    plt.plot(epochs, history.history['val_loss'], 'r', label='DoÄŸrulama KaybÄ±')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('EÄŸitim ve DoÄŸrulama KaybÄ±')
    plt.legend()

    # DoÄŸruluk (Accuracy) GrafiÄŸi
    plt.subplot(1, 2, 2)
    plt.plot(epochs, history.history['accuracy'], 'b', label='EÄŸitim DoÄŸruluÄŸu')
    plt.plot(epochs, history.history['val_accuracy'], 'r', label='DoÄŸrulama DoÄŸruluÄŸu')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.title('EÄŸitim ve DoÄŸrulama DoÄŸruluÄŸu')
    plt.legend()

    plt.show()

# EÄŸitim sÃ¼recini gÃ¶rselleÅŸtir
plot_training_history(history)

#%%

import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report

# Global test verisi (X_test_global, y_test_global) modelin daha Ã¶nce toplandÄ±ÄŸÄ±nÄ± varsayÄ±yoruz.
# Modelin global test verisi Ã¼zerindeki performansÄ±nÄ± Ã¶lÃ§elim:
test_loss, test_acc = model.evaluate(X_test, y_test)
print(f"\nTest Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2%}")

# Tahminleri al
y_pred_prob = model.predict(X_test)
y_pred = np.argmax(y_pred_prob, axis=1)
y_true = np.argmax(y_test, axis=1)

# Confusion Matrix oluÅŸtur
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Tahmin Edilen SÄ±nÄ±f")
plt.ylabel("GerÃ§ek SÄ±nÄ±f")
plt.title("Confusion Matrix")
plt.show()

# Classification Report
report = classification_report(y_true, y_pred)
print("Classification Report:\n", report)
